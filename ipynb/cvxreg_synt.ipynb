{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Regression\n",
    "\n",
    "Convex regression experiments on synthetic problems.\n",
    "\n",
    "### Important parameters:\n",
    "    - global_random_seed: the first initialization seed of the random number generator\n",
    "    - parallel_workers: the maximum number of parallel jobs (consider available RAM for choosing this too)\n",
    "    - domain_dims: domain dimensions (each of them defines a separate experiment)\n",
    "    - nsamples: sample sizes (each of them defines a separate experiment)\n",
    "    - nruns: number of runs for each experiment (statistics like mean, std, etc... are evaluated over the runs)\n",
    "    - estimators: estimators to be evaluated (uncomment the ones you want below)\n",
    "    - ntestsamples: number of test samples to use for the evaluation\n",
    "    \n",
    "Specify all the estimators to be used for all experiments in the *Estimators* section.<br>\n",
    "Specify one regression problem used for all experiments in the *Problem setting* section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '_MISSING_ID'  # Name your experiment here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 120\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "\n",
    "project_path = os.path.abspath('..')\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "print('project_path: {}'.format(project_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display\n",
    "\n",
    "from common.util import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    handlers=(\n",
    "        # logging.FileHandler('.../file.log'),\n",
    "        logging.StreamHandler(sys.stdout),\n",
    "    ),\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    format='%(asctime)s|%(levelname)s|%(message)s',\n",
    ")\n",
    "\n",
    "def info(*args):\n",
    "    logging.info('PID:{}|'.format(os.getpid()) + args[0] + '\\n', *args[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 10  # number of experiment runs\n",
    "ntestsamples = int(1e6)  # number of test samples to generate\n",
    "\n",
    "parallel_nworkers = 1  # maximum number of parallel workers (make sure you have enough RAM too)\n",
    "parallel_backend = 'multiprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_limit = 1e6\n",
    "global_random_seed = 100 + int(np.round((time.time() % 1) * seed_limit))\n",
    "set_random_seed(global_random_seed)\n",
    "setup_random_seed = np.random.randint(seed_limit)\n",
    "data_random_seed = np.random.randint(seed_limit)\n",
    "training_random_seed = np.random.randint(seed_limit)\n",
    "testing_random_seed = np.random.randint(seed_limit)\n",
    "info('random seeds, global:{}, setup:{}, data:{}, training:{}, testing:{}'.format(\n",
    "    global_random_seed, setup_random_seed, data_random_seed,\n",
    "    training_random_seed, testing_random_seed,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(setup_random_seed)\n",
    "estimators = OrderedDict()\n",
    "\n",
    "def get_estimator(estimator_name):\n",
    "    return estimators[estimator_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary Least-Squares estimator\n",
    "from common.ols import OLSEstimator\n",
    "estimators['OLS'] = OLSEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSPA\n",
    "# from y2009_lspa.lspa import LSPAEstimator\n",
    "# estimators['LSPA'] = LSPAEstimator(train_args={'ncenters': 'n**(d/(d+4))', 'nrestarts': 'd', 'nfinalsteps': 'n'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNLS\n",
    "from y2004_cnls.cnls import CNLSEstimator\n",
    "estimators['CNLS_star'] = CNLSEstimator(train_args={'use_L': True})\n",
    "estimators['CNLS_ln'] = CNLSEstimator(train_args={'use_L': True, 'ln_L': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convex Adaptive Partitioning (CAP)\n",
    "# from y2013_cap.cap import CAPEstimator\n",
    "# estimators['CAP'] = CAPEstimator()\n",
    "# # estimators['FastCAP'] = CAPEstimator(train_args={'nranddirs': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCNLS with random Voronoi partition\n",
    "# from y2015_pcnls.pcnls_voronoi import PCNLSVoronoiEstimator\n",
    "# estimators['PCNLS-Voronoi'] = PCNLSVoronoiEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adaptive Max-Affine Partitioning (AMAP)\n",
    "# from y2016_amap.amap import AMAPEstimator\n",
    "# estimators['AMAP'] = AMAPEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APCNLS\n",
    "from y2022_apcnls.apcnls import APCNLSEstimator\n",
    "estimators['APCNLS_star'] = APCNLSEstimator(train_args={'use_L': True})\n",
    "estimators['APCNLS_ln'] = APCNLSEstimator(train_args={'use_L': True, 'ln_L': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_caching_enabled = (global_random_seed < 100)  # caching is pointless without manual random seed setting\n",
    "if is_caching_enabled:\n",
    "    cache_dir = os.path.join(project_path, '_result_cache', experiment_id)\n",
    "    persister_dict = {}\n",
    "    for estimator_name in estimators.keys():\n",
    "        estimator_cache_dir = os.path.join(cache_dir, estimator_name)\n",
    "        os.makedirs(estimator_cache_dir, exist_ok=True)\n",
    "        persister_dict[estimator_name] = Memory(estimator_cache_dir, verbose=2)\n",
    "\n",
    "def cached_func(func, estimator_name):\n",
    "    if is_caching_enabled:\n",
    "        return persister_dict[estimator_name].cache(func)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_dims = (3,)  # domain dimensions\n",
    "nsamples = (100, 250)  # number of samples\n",
    "L = np.inf  # Lipschitz limit (can be set as a function to measure L on the union of the training and test sets)\n",
    "L_scaler = 1.0  # multiplying L (makes sense when L is measured on the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(yhat, y):  # L2-error\n",
    "    return np.mean(np.square(yhat - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Linear regression function\n",
    "# def fstar(X):\n",
    "#     return np.sum(X, axis=1)\n",
    "\n",
    "# L = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Symmetric L1-norm regression function\n",
    "# def fstar(X):\n",
    "#     return np.sum(np.abs(X), axis=1)\n",
    "\n",
    "# def L_func(X):\n",
    "#     return max(np.linalg.norm(np.sign(X), ord=2, axis=1))\n",
    "\n",
    "# L = L_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Truncated L1-norm regression function\n",
    "# def fstar(X):\n",
    "#     return np.sum(np.abs(np.maximum(X, 0.0)), axis=1)\n",
    "\n",
    "# def L_func(X):\n",
    "#     return max(np.linalg.norm(np.sign(np.maximum(X, 0.0)), ord=2, axis=1))\n",
    "\n",
    "# L = L_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetric quadratic regression function\n",
    "def fstar(X):\n",
    "    return 0.5 * np.sum(np.square(X), axis=1)\n",
    "\n",
    "def L_func(X):\n",
    "    return max(np.linalg.norm(X, ord=2, axis=1))\n",
    "\n",
    "L = L_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Truncated quadratic regression function\n",
    "# def fstar(X):\n",
    "#     return 0.5 * np.sum(np.square(np.maximum(X, 0.0)), axis=1)\n",
    "\n",
    "# def L_func(X):\n",
    "#     return max(np.linalg.norm(np.maximum(X, 0.0), ord=2, axis=1))\n",
    "\n",
    "# L = L_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariate distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full-dimensional Gaussian covariate\n",
    "covariate_std = 1.0\n",
    "\n",
    "def sample_X(n, d):\n",
    "    return np.random.randn(n, d) * covariate_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full-dimensional Uniform covariate\n",
    "# covariate_min = -1.0\n",
    "# covariate_max = 1.0\n",
    "\n",
    "# def sample_X(n, d):\n",
    "#     return np.random.rand(n, d) * (covariate_max - covariate_min) + covariate_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uniform random variable linearly embedded into a larger space with Gaussian measurement noise\n",
    "# low_d = 3\n",
    "# covariate_min = -3.0\n",
    "# covariate_max = 3.0\n",
    "# measurement_noise_std = 0.1\n",
    "\n",
    "# def sample_X(n, d):\n",
    "#     X = np.random.randn(n, d) * measurement_noise_std\n",
    "#     X[:, :low_d] = np.random.rand(n, low_d) * (covariate_max - covariate_min) + covariate_min\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uniform random variable with polynomial expansion and Gaussian measurement noise\n",
    "# covariate_min = -1.0\n",
    "# covariate_max = 1.0\n",
    "# measurement_noise_std = 0.1\n",
    "\n",
    "# def sample_X(n, d):\n",
    "#     X = np.random.randn(n, d) * measurement_noise_std\n",
    "#     Z = np.random.rand(n) * (covariate_max - covariate_min) + covariate_min\n",
    "#     for power in range(d):\n",
    "#         X[:, power] += Z**power\n",
    "#     return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation noise distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian observation noise\n",
    "observation_noise_std = 0.3\n",
    "\n",
    "def sample_noise(n):\n",
    "    return np.random.randn(n) * observation_noise_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rademacher observation noise\n",
    "\n",
    "# def sample_noise(n):\n",
    "#     return 2.0 * (np.random.randint(0, 2, n) - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed_offset(d, n, run):\n",
    "    return d * n + run\n",
    "\n",
    "\n",
    "def get_data(d, n, run, data_random_seed):\n",
    "    set_random_seed(data_random_seed + get_random_seed_offset(d, n, run))\n",
    "\n",
    "    X = sample_X(n, d)\n",
    "    y_true = fstar(X)\n",
    "    y = y_true + sample_noise(n)\n",
    "\n",
    "    X_test = sample_X(ntestsamples, d)\n",
    "    y_test = fstar(X_test)\n",
    "\n",
    "    return X, y, y_true, X_test, y_test\n",
    "\n",
    "\n",
    "def run_experiment(d, n, L, estimator_name, run, data_random_seed, training_random_seed):\n",
    "        X, y, y_true, X_test, y_test = get_data(d, n, run, data_random_seed)\n",
    "        L_true = max(L(X), L(X_test)) if callable(L) else L\n",
    "        Lscaler = eval(L_scaler) if isinstance(L_scaler, str) else L_scaler\n",
    "        L_est = (L_true * Lscaler) if np.isfinite(L_true) else np.inf\n",
    "\n",
    "        X_norms = np.linalg.norm(X, axis=1)\n",
    "        X_test_norms = np.linalg.norm(X_test, axis=1)\n",
    "        info(('\\nExperiment, d: {}, n: {}, estimator: {}, L_true: {:.1f}, run: {},\\n'\n",
    "              'train data, minX: {:.2f}, maxX: {:.2f}, minXnorm: {:.4f}, maxXnorm: {:.2f},\\n'\n",
    "              '            miny: {:.2f}, meany: {:.4f}, stdy: {:.4f}, maxy: {:.2f},\\n'\n",
    "              ' test data, minX: {:.2f}, maxX: {:.2f}, minXnorm: {:.4f}, maxXnorm: {:.2f},\\n'\n",
    "              '            miny: {:.2f}, meany: {:.4f}, stdy: {:.4f}, maxy: {:.2f},\\n').format(\n",
    "            d, n, estimator_name, L_true, run,\n",
    "            np.min(X), np.max(X), np.min(X_norms), np.max(X_norms),\n",
    "            np.min(y), np.mean(y), np.std(y), np.max(y),\n",
    "            np.min(X_test), np.max(X_test), np.min(X_test_norms), np.max(X_test_norms),\n",
    "            np.min(y_test), np.mean(y_test), np.std(y_test), np.max(y_test),\n",
    "        ))\n",
    "        set_random_seed(training_random_seed + get_random_seed_offset(d, n, run))\n",
    "        result = OrderedDict()\n",
    "        estimator = get_estimator(estimator_name)\n",
    "\n",
    "        train_args = OrderedDict()\n",
    "        if np.isfinite(L_est):\n",
    "            train_args['L'] = L_est\n",
    "        result['L_est'] = L_est\n",
    "        result['L_true'] = L_true\n",
    "\n",
    "        real_time, cpu_time = time.time(), time.clock()\n",
    "        model = estimator.train(X, y, **train_args)\n",
    "        result['model'] = model\n",
    "        result['nweights'] = model.weights.shape[0]\n",
    "        result['max_weight_norm'] = max(np.linalg.norm(model.weights, axis=1))\n",
    "        yhat = estimator.predict(model, X)\n",
    "        result['train_risk'] = loss(yhat, y)\n",
    "        result['train_err'] = loss(yhat, y_true)\n",
    "        result['train_diff_mean'] = np.mean(yhat - y)\n",
    "        result['train_diff_median'] = np.median(yhat - y)\n",
    "        result['train_cpu_time'] = time.clock() - cpu_time\n",
    "        result['train_real_time'] = time.time() - real_time\n",
    "\n",
    "        real_time, cpu_time = time.time(), time.clock()\n",
    "        yhat_test = estimator.predict(model, X_test)\n",
    "        result['test_err'] = loss(yhat_test, y_test)\n",
    "        result['test_cpu_time'] = time.clock() - cpu_time\n",
    "        result['test_real_time'] = time.time() - real_time\n",
    "\n",
    "        info(('\\nResult, d: {}, n: {}, estimator: {}, L_est: {:.1f}, run: {},\\n'\n",
    "              ' train, err: {:.4f}, risk: {:.4f}, real_time: {}s,\\n'\n",
    "              '  test, err: {:.4f}, real_time: {}s').format(\n",
    "            d, n, estimator_name, L_est, run,\n",
    "            result['train_err'], result['train_risk'], int(np.ceil(result['train_real_time'])),\n",
    "            result['test_err'], int(np.ceil(result['test_real_time'])),\n",
    "        ))\n",
    "        return ((d, n, estimator_name, run), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "delayed_funcs = []\n",
    "for d in domain_dims:\n",
    "    for n in nsamples:\n",
    "        for estimator_name in estimators.keys():\n",
    "            for run in range(nruns):\n",
    "                delayed_funcs.append(delayed(cached_func(run_experiment, estimator_name))(\n",
    "                    d, n, L, estimator_name, run,\n",
    "                    data_random_seed, training_random_seed,\n",
    "                ))\n",
    "results = OrderedDict(sorted(Parallel(n_jobs=parallel_nworkers, backend=parallel_backend)(delayed_funcs)))\n",
    "info('All results have been calculated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "def collect_stat_keys_and_values(results, estimator_name):\n",
    "    stat_keys = set()\n",
    "    stat_values = OrderedDict()\n",
    "    for k, r in results.items():\n",
    "        if k[-2] != estimator_name:\n",
    "            continue\n",
    "        stat_values.setdefault(k[:-2], []).append(r)\n",
    "        for sk in r.keys():\n",
    "            stat_keys.add(sk)\n",
    "    return stat_keys, stat_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printing common statistics.\n",
    "\n",
    "skipped_stats = ('model',)\n",
    "stat_funcs = OrderedDict((\n",
    "    ('mean', np.mean),\n",
    "    ('std', np.std),\n",
    "    ('min', np.min),\n",
    "    ('median', np.median),\n",
    "    ('max', np.max),\n",
    "))\n",
    "\n",
    "ds = set()\n",
    "stats = OrderedDict()\n",
    "for estimator_name in estimators.keys():\n",
    "    stat_keys, stat_values = collect_stat_keys_and_values(results, estimator_name)\n",
    "    stat = {}\n",
    "    for (d, n), s in stat_values.items():\n",
    "        ds.add(d)\n",
    "        ss = OrderedDict()\n",
    "        for sk in stat_keys:\n",
    "            if sk in skipped_stats:\n",
    "                continue\n",
    "            for sf_name, sf in stat_funcs.items():\n",
    "                ss[sk + '__' + sf_name] = sf([v[sk] for v in s])\n",
    "        stat[(d, n)] = ss\n",
    "    stat = pd.DataFrame(stat)\n",
    "    stat.columns.names = ('d', 'n')\n",
    "    print('\\nestimator: {}'.format(estimator_name))\n",
    "    stats[estimator_name] = stat\n",
    "    display(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting common statistics.\n",
    "\n",
    "skipped_estimators = []  # ['OLS']\n",
    "\n",
    "for d in ds:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    for estimator_name, stat in stats.items():\n",
    "        if estimator_name in skipped_estimators:\n",
    "            continue\n",
    "\n",
    "        stat = stat.T\n",
    "        stat = stat[stat.index.get_level_values(0) == d]\n",
    "        if not stat.empty:\n",
    "            ax1.set_title('d: {}, nruns: {}'.format(d, nruns))\n",
    "            ax1.set_xlabel('n')\n",
    "            ax1.set_ylabel('test error')\n",
    "            ax1.errorbar(\n",
    "                x=stat.index.get_level_values(1),\n",
    "                y=stat['test_err__mean'],\n",
    "                yerr=stat['test_err__std'],\n",
    "                label=estimator_name,\n",
    "            )\n",
    "            ax1.legend(loc='upper right')\n",
    "\n",
    "            ax2.set_title('d: {}, nruns: {}'.format(d, nruns))\n",
    "            ax2.set_xlabel('n')\n",
    "            ax2.set_ylabel('training risk')\n",
    "            ax2.errorbar(\n",
    "                x=stat.index.get_level_values(1),\n",
    "                y=stat['train_risk__mean'],\n",
    "                yerr=stat['train_risk__std'],\n",
    "                label=estimator_name,\n",
    "            )\n",
    "            ax2.legend(loc='upper right')\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    for estimator_name, stat in stats.items():\n",
    "        if estimator_name in skipped_estimators:\n",
    "            continue\n",
    "\n",
    "        stat = stat.T\n",
    "        stat = stat[stat.index.get_level_values(0) == d]\n",
    "        if not stat.empty:\n",
    "            ax1.set_title('d: {}, nruns: {}'.format(d, nruns))\n",
    "            ax1.set_xlabel('n')\n",
    "            ax1.set_ylabel('number of weight vectors')\n",
    "            ax1.errorbar(\n",
    "                x=stat.index.get_level_values(1),\n",
    "                y=stat['nweights__mean'],\n",
    "                yerr=stat['nweights__std'],\n",
    "                label=estimator_name,\n",
    "            )\n",
    "            ax1.legend(loc='upper right')\n",
    "\n",
    "            ax2.set_title('d: {}, nruns: {}'.format(d, nruns))\n",
    "            ax2.set_xlabel('n')\n",
    "            ax2.set_ylabel('training time (sec)')\n",
    "            ax2.errorbar(\n",
    "                x=stat.index.get_level_values(1),\n",
    "                y=stat['train_cpu_time__mean'],\n",
    "                yerr=stat['train_cpu_time__std'],\n",
    "                label=estimator_name,\n",
    "            )\n",
    "            ax2.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing estimator model specific statistics.\n",
    "\n",
    "estimator_names = []\n",
    "model_fields = []\n",
    "\n",
    "stats = OrderedDict()\n",
    "for estimator_name in estimators.keys():\n",
    "    if estimator_name not in estimator_names:\n",
    "        continue\n",
    "    stat_keys, stat_values = collect_stat_keys_and_values(results, estimator_name)\n",
    "    stat = {}\n",
    "    for (d, n), s in stat_values.items():\n",
    "        ss = OrderedDict()\n",
    "        for sk in stat_keys:\n",
    "            if sk != 'model':\n",
    "                continue\n",
    "            for field in model_fields:\n",
    "                for sf_name, sf in stat_funcs.items():\n",
    "                    vals = [v for v in [getattr(v[sk], field) for v in s] if v is not None]\n",
    "                    ss[field + '__' + sf_name] = None if len(vals) == 0 else sf(vals)\n",
    "        stat[(d, n)] = ss\n",
    "    stat = pd.DataFrame(stat)\n",
    "    stat.columns.names = ('d', 'n')\n",
    "    print('\\nestimator: {}'.format(estimator_name))\n",
    "    stats[estimator_name] = stat\n",
    "    display(stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
