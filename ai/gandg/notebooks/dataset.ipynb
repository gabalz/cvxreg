{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bc8d2f",
   "metadata": {
    "papermill": {
     "duration": 0.01236,
     "end_time": "2024-09-11T18:14:56.271315",
     "exception": false,
     "start_time": "2024-09-11T18:14:56.258955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset regression experiments <a class=\"anchor\" id=\"__dataset_top__\"></a>\n",
    "\n",
    "Convex and Lipschitz regression experiments on public datasets.<br/>\n",
    "See the [Notebook parameters](#__dataset_notebook_params__) cell for the settings.\n",
    "Select and configure the [estimators](#__dataset_estimators__).\n",
    "\n",
    "Go to the [performance results](#__dataset_notebook_results__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899083b-dbdf-4ad9-ac3e-d813ac4c7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b338b6",
   "metadata": {
    "papermill": {
     "duration": 0.103579,
     "end_time": "2024-09-11T18:14:57.538374",
     "exception": false,
     "start_time": "2024-09-11T18:14:57.434795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "project_path = os.path.abspath('.')\n",
    "while project_path != '/' and 'requirements.txt' not in os.listdir(project_path):\n",
    "    project_path = os.path.abspath(os.path.join(project_path, '..'))\n",
    "assert project_path != '/', 'Could not find project_path!'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "print('project_path: {}'.format(project_path))\n",
    "cache_data_dir = os.path.join(project_path, '_cache_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd68b68",
   "metadata": {
    "papermill": {
     "duration": 0.770194,
     "end_time": "2024-09-11T18:14:58.350603",
     "exception": false,
     "start_time": "2024-09-11T18:14:57.580409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display\n",
    "\n",
    "from ai.gandg.common.util import set_random_seed, eprint\n",
    "from ai.gandg.common.logging_helper import info, start_main_logging\n",
    "log_queue = start_main_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25deb764-5f0e-4b21-b850-5152ebfc94f2",
   "metadata": {
    "papermill": {
     "duration": 0.014685,
     "end_time": "2024-09-11T18:14:58.460329",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.445644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Notebook parameters <a id=\"__dataset_notebook_params__\"></a>\n",
    "[Go to the top.](#__dataset_top__)\n",
    "\n",
    "The next cell is tagged by <code>parameters</code> for [papermill](https://papermill.readthedocs.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d348be9",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.025269,
     "end_time": "2024-09-11T18:14:58.499923",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.474654",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is tagged 'parameters' for papermill.\n",
    "# These default parameter settings may be overwritten in the next cell.\n",
    "experiment_id = '_MISSING_ID'  # Name your experiment here!\n",
    "loss = 'l2'  # 'l2'\n",
    "data_name = 'cpusmall'\n",
    "#    'concrete', 'combined_cycle_power_plant', 'cpusmall',\n",
    "#    'red_wine', 'white_wine', 'parkinsons_telemonitoring',\n",
    "#    'nberces5818v1_n2012', 'nberces5818v1_n1997', 'nberces5818v1_s1987',\n",
    "#    'pumadyn-8nm', 'pumadyn-8nh', 'pumadyn-8fm', 'pumadyn-8fh',\n",
    "#    'pumadyn-32nm', 'pumadyn-32nh', 'pumadyn-32fm', 'pumadyn-32fh',\n",
    "nruns = 2  # number of evaluations of each experiment\n",
    "std_scaling = False\n",
    "min_max_scaling = False  # min/max scaling of the entire data\n",
    "normalize_data = True  # scalings to make |x-mean(x)| and |y-mean(y)| unit length\n",
    "shuffle_data = True  # whether or not to do an initial shuffle of the samples\n",
    "negate_target = False\n",
    "nsamples = 128,256,512  # number of training samples\n",
    "global_random_seed = None\n",
    "parallel_nworkers = 2  # maximum number of parallel workers (make sure yo u have enough RAM too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8083c0d-5899-4dc9-84f4-6bb0eb628167",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.033882,
     "end_time": "2024-09-11T18:14:58.617248",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.583366",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_int_tuple(param):\n",
    "    if isinstance(param, str):\n",
    "        return tuple([int(v) for v in param.split(',')])\n",
    "    elif isinstance(param, int):\n",
    "        return (param,)\n",
    "    return param\n",
    "\n",
    "if global_random_seed is not None:\n",
    "    global_random_seed = int(global_random_seed)\n",
    "nruns = int(nruns)\n",
    "nsamples = get_int_tuple(nsamples)\n",
    "negate_target = bool(negate_target)\n",
    "std_scaling = bool(std_scaling)\n",
    "min_max_scaling = bool(min_max_scaling)\n",
    "normalize_data = bool(normalize_data)\n",
    "shuffle_data = bool(shuffle_data)\n",
    "parallel_nworkers = int(parallel_nworkers)\n",
    "assert (not std_scaling) or (not min_max_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dad00a",
   "metadata": {
    "papermill": {
     "duration": 0.036439,
     "end_time": "2024-09-11T18:14:58.690540",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.654101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_limit = 1e6\n",
    "if global_random_seed is None:\n",
    "    global_random_seed = 10000 + int(np.round((time.time() % 1) * seed_limit))\n",
    "set_random_seed(global_random_seed)\n",
    "setup_random_seed = np.random.randint(seed_limit)\n",
    "data_random_seed = np.random.randint(seed_limit)\n",
    "experiment_random_seed = np.random.randint(seed_limit)\n",
    "training_random_seed = np.random.randint(seed_limit)\n",
    "testing_random_seed = np.random.randint(seed_limit)\n",
    "info('random seeds, global:{}, setup:{}, data:{}, exp:{}, training:{}, testing:{}'.format(\n",
    "    global_random_seed, setup_random_seed, data_random_seed,\n",
    "    experiment_random_seed, training_random_seed, testing_random_seed,\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04338dec-cf12-485e-af83-f95df1e31061",
   "metadata": {
    "papermill": {
     "duration": 0.012633,
     "end_time": "2024-09-11T18:14:59.384573",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.371940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Problem setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c6f51-d1c3-46fe-9139-9c088edac54e",
   "metadata": {
    "papermill": {
     "duration": 0.049314,
     "end_time": "2024-09-11T18:14:59.448141",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.398827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_convex = False\n",
    "if data_name == 'concrete':\n",
    "    dataset = 'UCI:165:concrete_data.csv'  # https://doi.org/10.24432/C5PK67\n",
    "    data_reader_fn = pd.read_csv\n",
    "\n",
    "    def prepare_data(df):  # X.shape == (1030, 8)\n",
    "        target_label = 'Concrete compressive strength'\n",
    "        y = df.loc[:, target_label]\n",
    "        X = df.drop(['Unnamed: 0', target_label], axis=1)\n",
    "        return X, y\n",
    "\n",
    "elif data_name == 'combined_cycle_power_plant':\n",
    "    dataset = 'UCI:294:combined_cycle_power_plant.csv'  # https://doi.org/10.24432/C5002N\n",
    "    data_reader_fn = pd.read_csv\n",
    "    \n",
    "    def prepare_data(df):\n",
    "        y = df['PE']\n",
    "        X = df.drop(['Unnamed: 0', 'PE'], axis=1)\n",
    "        return X, y\n",
    "\n",
    "elif data_name in ('red_wine', 'white_wine'):\n",
    "    wine_color = data_name.split('_')[0]\n",
    "    dataset = f'UCI:186:{wine_color}_wine_data.csv'  # https://doi.org/10.24432/C56S3T\n",
    "    data_reader_fn = pd.read_csv\n",
    "    \n",
    "    def prepare_data(df):\n",
    "        index_label = 'Unnamed: 0'\n",
    "        index = df.loc[:, index_label]\n",
    "        df = df.drop(index_label, axis=1)\n",
    "        if wine_color == 'red':\n",
    "            df = df[index < 1599]\n",
    "        elif wine_color == 'white':\n",
    "            df = df[index >= 1599]\n",
    "        else:\n",
    "            print(f'Invalid wine_color: {wine_color}')\n",
    "        y = df['quality']\n",
    "        X = df.drop('quality', axis=1)\n",
    "        return X, y\n",
    "\n",
    "elif data_name == 'parkinsons_telemonitoring':\n",
    "    dataset = 'UCI:189:parkinsons_telemonitoring.csv'\n",
    "    target_label = 'total_UPDRS'\n",
    "    # target_label = 'motor_UPDRS'\n",
    "    data_reader_fn = pd.read_csv\n",
    "    \n",
    "    def prepare_data(df):  # X.shape == (5875, 17)\n",
    "        y = df[target_label]\n",
    "        X = df.drop(['Unnamed: 0', 'total_UPDRS', 'motor_UPDRS'], axis=1)\n",
    "        return X, y\n",
    "\n",
    "elif data_name.startswith('nberces5818v1_'):\n",
    "    dataset = f\"https://data.nber.org//nberces/nberces5818v1/{data_name}.csv\"\n",
    "    data_reader_fn = pd.read_csv\n",
    "    \n",
    "    def prepare_data(df, filter_year=(2000, 2015)):\n",
    "        X = df[['year', 'vship', 'cap', 'prodh', 'emp', 'prode']]\n",
    "        if filter_year is not None:\n",
    "            if isinstance(filter_year, int):\n",
    "                X = X[X['year'] == filter_year]\n",
    "            else:\n",
    "                X = X[X['year'].between(*filter_year)]\n",
    "            X = X.drop('year', axis=1).reset_index(drop=True)\n",
    "        X['emp-prode'] = X['emp'] - X['prode']\n",
    "        X = np.log(np.maximum(0.1, X))\n",
    "        y = X['vship']\n",
    "        X.drop(['vship', 'emp'], axis=1, inplace=True)\n",
    "        return X, y\n",
    "\n",
    "elif data_name == 'cpusmall':\n",
    "    dataset = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/cpusmall\"\n",
    "    \n",
    "    def data_reader_fn(dataset):\n",
    "        df = pd.read_csv(dataset, sep=' ', header=None)\n",
    "        df = df.apply(lambda ser:\n",
    "                      ser if ser.dtype != 'object'\n",
    "                      else ser.map(lambda s: s.split(':')[-1]))\n",
    "        return df\n",
    "    \n",
    "    def prepare_data(df):\n",
    "        y = df.iloc[:, 0]\n",
    "        X = df.iloc[:, 1:]\n",
    "        return X, y\n",
    "\n",
    "elif data_name.startswith('pumadyn-'):\n",
    "    dataset = os.path.join(cache_data_dir, data_name)\n",
    "    if not os.path.isdir(dataset):\n",
    "        raise Exception(f'Dataset {data_name} has to be downloaded manually'\n",
    "                        f' and unpacked into directory: {cache_data_dir}!')\n",
    "\n",
    "    def data_reader_fn(dataset):\n",
    "        return pd.read_csv(os.path.join(dataset, 'accel/Prototask.data.gz'), header=None, sep='\\s+')\n",
    "        # return pd.read_csv(os.path.join(dataset, 'Dataset.data.gz'), header=None, sep='\\s+')\n",
    "\n",
    "    def prepare_data(df):\n",
    "        y = df.iloc[:, -1]\n",
    "        X = df.iloc[:, :-1]\n",
    "        if '32' in data_name:\n",
    "            X = pd.concat([X.iloc[:, :12], X.iloc[:, 12:17] / 10000.0, X.iloc[:, 17:]], axis=1)\n",
    "        return X, y\n",
    "\n",
    "else:\n",
    "    raise Exception(f'Unknown data_name: {data_name}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af192977",
   "metadata": {
    "papermill": {
     "duration": 0.033555,
     "end_time": "2024-09-11T18:14:59.523218",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.489663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ai.gandg.common.experiment import loss_l1, loss_l2, loss_linf\n",
    "\n",
    "report_loss_name = loss\n",
    "stat_losses = {'l1': loss_l1, 'l2': loss_l2, 'linf': loss_linf}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42f65b",
   "metadata": {
    "papermill": {
     "duration": 0.014978,
     "end_time": "2024-09-11T18:14:58.722192",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.707214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Estimators <a class=\"anchor\" id=\"__dataset_estimators__\"></a>\n",
    "[Go to the top.](#__dataset_top__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101c28",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.062313,
     "end_time": "2024-09-11T18:14:58.799001",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.736688",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ai.gandg.common.estimator import Estimator, EstimatorModel, ConstEstimator\n",
    "\n",
    "set_random_seed(setup_random_seed)\n",
    "estimators = OrderedDict()\n",
    "\n",
    "def get_estimator(estimator_name):\n",
    "    return estimators[estimator_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f211cf77",
   "metadata": {
    "papermill": {
     "duration": 0.036865,
     "end_time": "2024-09-11T18:14:58.851385",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.814520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ordinary Least-Squares estimator\n",
    "from ai.gandg.common.ols import OLSEstimator\n",
    "estimators['OLS'] = OLSEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46411c-c5b4-4b7c-9c9c-fc646871a699",
   "metadata": {
    "papermill": {
     "duration": 0.030107,
     "end_time": "2024-09-11T18:14:58.921753",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.891646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "from ai.gandg.algorithm.external.xgboost import XgbEstimator\n",
    "estimators['XGB'] = XgbEstimator(objective='reg:absoluteerror') if loss == 'l1' else XgbEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd682c8d-b7ec-4e53-8d07-3e6d746912b4",
   "metadata": {
    "papermill": {
     "duration": 0.030908,
     "end_time": "2024-09-11T18:14:58.965677",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.934769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "from ai.gandg.algorithm.external.random_forest import RandomForestEstimator\n",
    "estimators['RF'] = RandomForestEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7c77d-fb62-4493-ac2a-ff3c844d7f26",
   "metadata": {
    "papermill": {
     "duration": 0.06316,
     "end_time": "2024-09-11T18:14:59.042953",
     "exception": false,
     "start_time": "2024-09-11T18:14:58.979793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # !pip install scikit-learn\n",
    "from ai.gandg.algorithm.external.nearest_neighbors import NearestNeighborsEstimator\n",
    "# # estimators['KNN1'] = NearestNeighborsEstimator(n_neighbors=1)\n",
    "# # estimators['KNN5'] = NearestNeighborsEstimator(n_neighbors=5)\n",
    "# # estimators['KNN+'] = NearestNeighborsEstimator(n_neighbors='AFPC', cv=5, afpc_ntrials=10)\n",
    "# estimators['KNN*'] = NearestNeighborsEstimator(n_neighbors='n**(d/(2+d))', cv=5)\n",
    "estimators['KNN'] = NearestNeighborsEstimator(n_neighbors='np.log(n)*n**(2/(2+d))', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c781a8-59f6-4b39-b79e-6261d5f259e9",
   "metadata": {
    "papermill": {
     "duration": 0.22512,
     "end_time": "2024-09-11T18:14:59.282300",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.057180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # !pip install scikit-learn scikit-fda\n",
    "from ai.gandg.algorithm.external.kernel_regression import KernelRegEstimator\n",
    "estimators['kreg_nor'] = KernelRegEstimator('normal')\n",
    "# estimators['kreg_epa'] = KernelRegEstimator('epanechnikov')\n",
    "# estimators['kreg_tri'] = KernelRegEstimator('tri_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9567f7-2941-4b79-89ed-292ad3ce8454",
   "metadata": {
    "editable": true,
    "papermill": {
     "duration": 0.03959,
     "end_time": "2024-09-11T18:14:59.334857",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.295267",
     "status": "completed"
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delta-Convex Fitting (DCF)\n",
    "from ai.gandg.algorithm.dcf.dcf import DCFEstimator\n",
    "from ai.gandg.optim.socprog import SOCP_BACKEND__CLARABEL, SOCP_BACKEND__LBFGS\n",
    "\n",
    "dcf_train_args = {\n",
    "    # 'verbose': 0,\n",
    "    # 'local_opt_type': 'smooth',\n",
    "    # 'normalize': True,\n",
    "    # 'L_sum_regularizer': '(x_radius/n)**2',\n",
    "    # 'L_regularizer': 'max(1.0, x_radius)**2 * (d*K/n)',\n",
    "    # 'L_regularizer_offset': '(y_radius/x_radius)*np.log(n)',\n",
    "    # 'local_opt_L_regularizer_offset': 'np.log(n)',\n",
    "    # 'backend': SOCP_BACKEND__LBFGS,  # SOCP_BACKEND__LBFGS or SOCP_BACKEND__CLARABEL\n",
    "}\n",
    "# estimators['DCF1'] = DCFEstimator(variant=1, train_args=dcf_train_args)\n",
    "# estimators['DCF1-'] = DCFEstimator(variant=1, negate_y=True, train_args=dcf_train_args)\n",
    "estimators['DCFi'] = DCFEstimator(variant=np.inf, train_args=dcf_train_args)\n",
    "estimators['DCFi-'] = DCFEstimator(variant=np.inf, negate_y=True, train_args=dcf_train_args)\n",
    "# estimators['DCF2'] = DCFEstimator(variant=2, train_args=dcf_train_args)\n",
    "# estimators['DCF2-'] = DCFEstimator(variant=2, negate_y=True, train_args=dcf_train_args)\n",
    "estimators['DCF+'] = DCFEstimator(variant='+', train_args=dcf_train_args)\n",
    "estimators['DCF+-'] = DCFEstimator(variant='+', negate_y=True, train_args=dcf_train_args)\n",
    "# # # Symmetrized DCF variants:\n",
    "# estimators['DCF1s'] = DCFEstimator(variant=1, is_symmetrized=True, train_args=dcf_train_args)\n",
    "# estimators['DCFis'] = DCFEstimator(variant=np.inf, is_symmetrized=True, train_args=dcf_train_args)\n",
    "estimators['DCF2s'] = DCFEstimator(variant=2, is_symmetrized=True, train_args=dcf_train_args)\n",
    "estimators['DCF+s'] = DCFEstimator(variant='+', is_symmetrized=True, train_args=dcf_train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710bb49b-e5db-4c9c-add5-e33b2131895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators['MMA'] = DCFEstimator(variant='mma', is_symmetrized=False, train_args=dcf_train_args)\n",
    "# estimators['MMAs'] = DCFEstimator(variant='mma', is_symmetrized=True, train_args=dcf_train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63952df3-682c-4cce-bee9-02995d6a80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delta-Convex Fitting (initial solutions, iDCF)\n",
    "\n",
    "# dcf_train_args_i = dict(dcf_train_args)\n",
    "# dcf_train_args_i['local_opt_maxiter'] = 0\n",
    "\n",
    "# estimators['iDCFi'] = DCFEstimator(variant=np.inf, train_args=dcf_train_args_i)\n",
    "# estimators['iDCFi-'] = DCFEstimator(variant=np.inf, negate_y=True, train_args=dcf_train_args_i)\n",
    "# estimators['iDCFis'] = DCFEstimator(variant=np.inf, is_symmetrized=True, train_args=dcf_train_args_i)\n",
    "# estimators['iDCF+'] = DCFEstimator(variant='+', train_args=dcf_train_args_i)\n",
    "# estimators['iDCF+-'] = DCFEstimator(variant='+', negate_y=True, train_args=dcf_train_args_i)\n",
    "# estimators['iDCF+s'] = DCFEstimator(variant='+', is_symmetrized=True, train_args=dcf_train_args_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a5580-144d-43a1-960b-f21143050927",
   "metadata": {
    "papermill": {
     "duration": 0.020976,
     "end_time": "2024-09-11T18:14:59.562868",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.541892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9cd696-0d7d-4e0d-89d7-78d4eb7f10da",
   "metadata": {
    "papermill": {
     "duration": 0.164079,
     "end_time": "2024-09-11T18:14:59.739698",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.575619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_raw_data(\n",
    "    dataset, reader_fn=pd.read_csv,\n",
    "    shuffle_data=False, data_dir=cache_data_dir,\n",
    "    min_max_scaling=False, std_scaling=False,\n",
    "):\n",
    "    is_uci = dataset.startswith('UCI:')\n",
    "    fname = dataset.split(':')[-1] if is_uci else os.path.basename(dataset)\n",
    "    raw_data_fpath = os.path.join(data_dir, fname)\n",
    "    if not os.path.exists(raw_data_fpath):\n",
    "        print('Downloading raw data ...', end='')\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        if is_uci:\n",
    "            from ucimlrepo import fetch_ucirepo\n",
    "            data = fetch_ucirepo(id=int(dataset.split(':')[1]))\n",
    "            df = pd.concat([data.data.features, data.data.targets], axis=1)\n",
    "            df.to_csv(raw_data_fpath)\n",
    "        else:\n",
    "            import requests\n",
    "            with open(raw_data_fpath, 'wb') as f:\n",
    "                f.write(requests.get(dataset).content)\n",
    "        print(' done')\n",
    "        print(f'Raw data is saved to: {raw_data_fpath}')\n",
    "    print(f'Loading raw data from: {raw_data_fpath}')\n",
    "    df = reader_fn(raw_data_fpath)\n",
    "    df = df.astype(float)\n",
    "    if shuffle_data:\n",
    "        print('Data is shuffled.')\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    if min_max_scaling:\n",
    "        df_min = df.min(axis=0)\n",
    "        df -= df_min\n",
    "        print(f'\\nmin_max_scaling, df_min:\\n{df_min}')\n",
    "        df_max = df.max(axis=0)\n",
    "        df /= df_max\n",
    "        print(f'\\nmin_max_scaling, df_max:\\n{df_max}')\n",
    "    elif std_scaling:\n",
    "        df -= df.mean(axis=0)\n",
    "        df_std = df.std(axis=0)\n",
    "        df /= df_std\n",
    "        print(f'std_scaling, df_std:\\n{df_std}')\n",
    "    return df\n",
    "\n",
    "\n",
    "set_random_seed(data_random_seed)\n",
    "X, y = prepare_data(get_raw_data(dataset,\n",
    "                                 reader_fn=data_reader_fn,\n",
    "                                 shuffle_data=shuffle_data,\n",
    "                                 std_scaling=std_scaling,\n",
    "                                 min_max_scaling=min_max_scaling))\n",
    "\n",
    "def data_normalizer(X, y):\n",
    "    X -= np.mean(X, axis=0)\n",
    "    sx = np.linalg.norm(X, ord='fro') / np.sqrt(X.shape[0])\n",
    "    X /= sx\n",
    "    y -= np.mean(y)\n",
    "    sy = np.std(y)\n",
    "    y /= sy\n",
    "    print(f\"data normalization, sx: {sx:.4f}, sy: {sy:.4f}\")\n",
    "    return X, y\n",
    "\n",
    "if normalize_data:\n",
    "    X, y = data_normalizer(X, y)\n",
    "print(f'\\nX.shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4ff2d-9862-47a4-a1d5-7bb5df1039f4",
   "metadata": {
    "papermill": {
     "duration": 0.186334,
     "end_time": "2024-09-11T18:14:59.939221",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.752887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Feature statistics:')\n",
    "X.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f747e053-1b0f-4817-b412-38090a049d3e",
   "metadata": {
    "papermill": {
     "duration": 0.048963,
     "end_time": "2024-09-11T18:15:00.002046",
     "exception": false,
     "start_time": "2024-09-11T18:14:59.953083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Response statistics:')\n",
    "pd.DataFrame(y).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b9eb7d-dbb4-4506-a6d3-a74bc087e126",
   "metadata": {
    "papermill": {
     "duration": 0.01472,
     "end_time": "2024-09-11T18:15:00.032450",
     "exception": false,
     "start_time": "2024-09-11T18:15:00.017730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b0e32",
   "metadata": {
    "papermill": {
     "duration": 0.069377,
     "end_time": "2024-09-11T18:15:00.118328",
     "exception": false,
     "start_time": "2024-09-11T18:15:00.048951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ai.gandg.common.cache import ResultCache\n",
    "result_cache = ResultCache(\n",
    "    is_enabled=(global_random_seed < 10000), # caching is pointless without manual random seed setting\n",
    "    project_path=project_path,\n",
    "    experiment_id=experiment_id,\n",
    ")\n",
    "print(f'is_caching_enabled: {result_cache.is_enabled()}')\n",
    "output_dir = None\n",
    "if result_cache.is_enabled():\n",
    "    output_dir = os.path.join(result_cache.cache_dir,\n",
    "                              f'stats-seed{global_random_seed}-r{nruns}'\n",
    "                              + '-n' + ','.join([str(n) for n in nsamples]))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f'output_dir: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8744a1-0f29-4d1d-97af-abae494e67e6",
   "metadata": {
    "papermill": {
     "duration": 0.01921,
     "end_time": "2024-09-11T18:15:00.160155",
     "exception": false,
     "start_time": "2024-09-11T18:15:00.140945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2780c9-b1d2-4100-84b0-3dddb41f29b7",
   "metadata": {
    "papermill": {
     "duration": 0.071451,
     "end_time": "2024-09-11T18:15:00.251371",
     "exception": false,
     "start_time": "2024-09-11T18:15:00.179920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ai.gandg.common.experiment import get_random_seed_offset\n",
    "\n",
    "def get_data(n, run, data_random_seed):\n",
    "    d = X.shape[1]\n",
    "    seed = data_random_seed + get_random_seed_offset(d, n, run)\n",
    "    print(f'seed: {seed}, d:{d}, n:{n}, run:{run}, data_random_seed:{data_random_seed}')\n",
    "    set_random_seed(seed)\n",
    "\n",
    "    assert n < len(y), f'Too few data, n:{n}, len(y):{len(y)}'\n",
    "    sample_range = np.arange(len(y))\n",
    "    train_index = np.random.choice(sample_range, size=n, replace=False)\n",
    "    test_index = np.setdiff1d(sample_range, train_index, assume_unique=True)\n",
    "    X_train = X.iloc[train_index, :].values.copy()\n",
    "    y_train = y.iloc[train_index].values.copy()\n",
    "    X_test = X.iloc[test_index, :].values.copy()\n",
    "    y_test = y.iloc[test_index].values.copy()\n",
    "    if negate_target:\n",
    "        y_train = -y_train\n",
    "        y_test = -y_test\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71541f70-704c-406e-b225-2405ead274d2",
   "metadata": {},
   "source": [
    "### AFPC statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f8ec3-872e-406c-abbc-0b0d6e21bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clustering(data):\n",
    "    from ai.gandg.algorithm.apcnls.fpc import adaptive_farthest_point_clustering\n",
    "    partition, center_idx = adaptive_farthest_point_clustering(\n",
    "        data=data, q=1, return_center_idxs=True,\n",
    "    )\n",
    "    return partition, data[center_idx, :]\n",
    "    # from algorithm.dcf.dcf import get_dcf_partition\n",
    "    # n, d = data.shape\n",
    "    # def get_dcf_param(param, default, n, d):\n",
    "    #     value = dcf_train_args.get(param, default)\n",
    "    #     if isinstance(value, str):\n",
    "    #         value = eval(value)\n",
    "    #     return value\n",
    "    # return get_dcf_partition(\n",
    "    #     data,\n",
    "    #     ntrials=get_dcf_param('afpc_ntrials', 1, n, d),\n",
    "    #     min_cell_size=get_dcf_param('afpc_min_cell_size', 0, n, d),\n",
    "    #     kmeans_objval=get_dcf_param('kmeans_objval', False, n, d),\n",
    "    #     kmeans_kwargs=get_dcf_param('kmeans_kwargs', None, n, d),\n",
    "    # )[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd85b7-a9b2-49d2-9743-5398c0363471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.notebooks.clustering_stats import (\n",
    "    get_clustering_stats, plot_partition_size, plot_partition_epsilon,\n",
    ")\n",
    "\n",
    "afpc_stats = get_clustering_stats(\n",
    "    nsamples=nsamples,\n",
    "    nruns=nruns,\n",
    "    data_random_seed=data_random_seed,\n",
    "    get_data_func=get_data,\n",
    "    get_cluster_func=get_clustering,\n",
    "    report_loss=stat_losses[report_loss_name],\n",
    ")\n",
    "print('\\nData statistics:')\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(afpc_stats)\n",
    "if output_dir is not None:\n",
    "    afpc_stats.to_csv(os.path.join(output_dir, 'data_stats.csv'))\n",
    "\n",
    "d = X.shape[1]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 4))\n",
    "plot_partition_size(ax1, d, nsamples, afpc_stats)\n",
    "plot_partition_epsilon(ax2, d, nsamples, afpc_stats)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed155b-8f04-464b-99cc-9d9199fa15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.notebooks.clustering_stats import (\n",
    "    get_clustering_cell_size_distribution,\n",
    "    plot_partition_cell_size_distribution,\n",
    ")\n",
    "max_n = max(nsamples)\n",
    "afpc_cs_stats = get_clustering_cell_size_distribution(\n",
    "    max_n, nruns, data_random_seed,\n",
    "    get_data_func=get_data, get_cluster_func=get_clustering,\n",
    ")\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "plot_partition_cell_size_distribution(ax1, d, afpc_cs_stats, n=max_n)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f4cfe",
   "metadata": {
    "papermill": {
     "duration": 0.124487,
     "end_time": "2024-09-11T18:15:06.980704",
     "exception": false,
     "start_time": "2024-09-11T18:15:06.856217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c9d52",
   "metadata": {
    "papermill": {
     "duration": 0.08694,
     "end_time": "2024-09-11T18:15:07.103298",
     "exception": false,
     "start_time": "2024-09-11T18:15:07.016358",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ai.gandg.common.experiment import (\n",
    "    calc_experiment_result,\n",
    "    prepare_experiment_calc_funcs,\n",
    ")\n",
    "\n",
    "def run_experiment(n, estimator_name, run, data_random_seed, training_random_seed):\n",
    "    result = calc_experiment_result(\n",
    "        n=n, estimator_name=estimator_name, run=run,\n",
    "        get_data_func=get_data, get_estimator_func=get_estimator,\n",
    "        stat_losses=stat_losses, report_loss_name=report_loss_name, log_queue=log_queue,\n",
    "        data_random_seed=data_random_seed, training_random_seed=training_random_seed,\n",
    "    )\n",
    "    return ((n, estimator_name, run), result)\n",
    "\n",
    "delayed_funcs = prepare_experiment_calc_funcs(\n",
    "    nsamples=nsamples, nruns=nruns, estimators=estimators,\n",
    "    data_random_seed=data_random_seed, training_random_seed=training_random_seed,\n",
    "    result_cache=result_cache, run_experiment_func=run_experiment,\n",
    ")\n",
    "try:\n",
    "    results = OrderedDict(sorted(Parallel(n_jobs=parallel_nworkers)(delayed_funcs)))\n",
    "except Exception:\n",
    "    eprint(traceback.format_exc())\n",
    "    time.sleep(3)\n",
    "    raise\n",
    "info('All results have been calculated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbfb24-dacb-45a4-b419-231a0a5e58cf",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769ce3e-0795-4333-98fd-984fc7100939",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_estimators = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d57a23-9bdd-46cf-83cf-41bc1af82530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.common.experiment import collect_estimator_stats\n",
    "\n",
    "all_stats = OrderedDict()\n",
    "for estimator_name in list(estimators.keys()):\n",
    "    stats = collect_estimator_stats(estimator_name, results)\n",
    "    print('\\nestimator: {}'.format(estimator_name))\n",
    "    all_stats[estimator_name] = stats\n",
    "    with pd.option_context('display.max_rows', None):\n",
    "        display(stats)\n",
    "\n",
    "if output_dir is not None:\n",
    "    for k, v in all_stats.items():\n",
    "        v.to_csv(os.path.join(output_dir, f'stats-{k}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f60d83-23cc-4ac7-9938-858e74c5d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.notebooks.evaluation import plot_standard_stats\n",
    "\n",
    "plot_standard_stats(\n",
    "    all_stats=all_stats, report_loss_name=report_loss_name,\n",
    "    skipped_estimators=skipped_estimators,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56be05-6204-48c0-8c9c-78084e3bb0a3",
   "metadata": {},
   "source": [
    "### Test L2-risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82421b8-2221-4dd6-bdff-744ee28389cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.common.experiment import collect_stats_by_name\n",
    "\n",
    "test_risk = pd.concat([\n",
    "    collect_stats_by_name(all_stats, 'test_l2-risk__mean'),\n",
    "    collect_stats_by_name(all_stats, 'test_l2-risk__std'),\n",
    "], axis=1, keys=['mean', 'std']).swaplevel(0, 1, axis=1).sort_index(axis=1)\n",
    "\n",
    "print('Test risk:')\n",
    "display(np.round(test_risk, decimals=4).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a89d1f-86ea-4df5-b9c4-2193969ca7e7",
   "metadata": {},
   "source": [
    "## Performance <a id=\"__dataset_notebook_results__\"></a>\n",
    "[Go to the top.](#__dataset_top__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ea8f2-8b45-477a-854b-5e6f289deef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.notebooks.evaluation import plot_bar_perf\n",
    "\n",
    "estimator_names = OrderedDict([\n",
    "    ('KNN', 'k-NN'),\n",
    "    ('kreg_nor', 'NW-G'),\n",
    "    ('kreg_tri', 'NW-T'),\n",
    "    ('DCFi', r'$\\textrm{DCF}_{\\hspace{-1mm}\\infty}$'),\n",
    "    ('DCFi-', r'$\\textrm{DCF}_{\\hspace{-1mm}\\infty}^-$'),\n",
    "    ('DCF2s', r'$\\textrm{DCF}_{\\hspace{-1mm}2}^\\Delta$'),\n",
    "    ('DCFis', r'$\\textrm{DCF}_{\\hspace{-1mm}\\infty}^\\Delta$'),\n",
    "    ('MMA', r'$\\textrm{MMA}$'),\n",
    "    ('MMAs', r'$\\textrm{MMA}^\\Delta$'),\n",
    "    ('DCF+', r'$\\textrm{DCF}_{\\hspace{-1mm}+}$'),\n",
    "    ('DCF+-', r'$\\textrm{DCF}_{\\hspace{-1mm}+}^-$'),\n",
    "    ('DCF+s', r'$\\textrm{DCF}_{\\hspace{-1mm}+}^\\Delta$'),\n",
    "    ('RF', 'RF'),\n",
    "    ('XGB', 'XGB'),\n",
    "    ('OLS', 'OLS'),\n",
    "    ('iDCF+s', r'$\\textrm{i-DCF}_{\\hspace{-1mm}+}^\\Delta$'),\n",
    "])\n",
    "estimator_names = {k: v for k, v in estimator_names.items() if k in estimators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31601b6f-c07f-450d-afd1-9eea4ece4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = 'noFS'\n",
    "if min_max_scaling:\n",
    "    scaling = 'MM'\n",
    "elif std_scaling:\n",
    "    scaling = 'STD'\n",
    "\n",
    "title=f'{data_name} ({scaling})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142bdc7-fb2c-4647-85ea-0469471c219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_perf(results, 'train_l2-risk', estimator_names, ylabel='Train MSE', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19217fec-3545-4b91-af55-a1adb4704a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_perf(results, 'test_l2-risk', estimator_names, ylabel='Test MSE', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d21b8-5b65-4022-9e77-e3c8fc519f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_perf(results, 'train_real_time', estimator_names, yscale='log', ylabel='train.(s, log scale)', title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75630c45-9de8-46c7-bab7-700c67b8597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_perf(results, 'test_real_time', estimator_names, yscale='log', ylabel='pred.(ms, log scale)',\n",
    "              title=title, nscale={n: 1e6/(len(y)-n) for n in nsamples})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0254b28-0435-41e8-bebb-a8bd02fd6a62",
   "metadata": {},
   "source": [
    "## Extra analysis for DCF estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c80658-617e-46c8-b7c4-51f07d43c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf_estimator_names = {k: v for k, v in estimator_names.items()\n",
    "                       if k.startswith('DCF') or k.startswith('MMA')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d27c8a0-37fa-4765-8c96-1af7190d9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai.gandg.notebooks.evaluation import (\n",
    "    plot_dcf_nparams,\n",
    "    plot_dcf_training_times,\n",
    "    plot_dcf_niterations,\n",
    "    print_dcf_lipschitz_constants,\n",
    ")\n",
    "plot_dcf_nparams(results, dcf_estimator_names, max_n)\n",
    "plot_dcf_training_times(results, dcf_estimator_names, max_n)\n",
    "plot_dcf_niterations(results, dcf_estimator_names, max_n)\n",
    "print('DCF Lipschitz constants:')\n",
    "print_dcf_lipschitz_constants(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37be9165-020e-403d-a330-91b96d333162",
   "metadata": {},
   "outputs": [],
   "source": [
    "!date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20396.268955,
   "end_time": "2024-09-11T23:54:50.423981",
   "environment_variables": {},
   "exception": null,
   "input_path": "ipynb/real_world.ipynb",
   "output_path": "ipynb/_real_world__l2__cpusmall.ipynb",
   "parameters": {
    "data_name": "cpusmall",
    "experiment_id": "l2__cpusmall",
    "global_random_seed": 1819,
    "loss": "l2",
    "nruns": 20,
    "nsamples": "4000,2000,1000,500",
    "parallel_nworkers": 1
   },
   "start_time": "2024-09-11T18:14:54.155026",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
